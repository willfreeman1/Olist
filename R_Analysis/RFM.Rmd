---
title: RFM
output: html_notebook
---
```{r}
RFM_DF = ord_cust_pay_geo_prod
```

```{r}
# Convert order timestam to datetime
head(RFM_DF$order_purchase_timestamp)

RFM_DF$order_purchase_timestamp <- as.character(RFM_DF$order_purchase_timestamp)


RFM_DF$order_purchase_timestamp = as.POSIXct(RFM_DF$order_purchase_timestamp, format = "%Y-%m-%d %H:%M:%S")

str(RFM_DF$order_purchase_timestamp)

```
```{r}
# Calc Recency

# Find the most recent purchase date in the dataset
most_recent_purchase <- max(RFM_DF$order_purchase_timestamp, na.rm = TRUE)

# Calculate Recency
recency_df <- RFM_DF %>%
  group_by(customer_unique_id) %>%
  summarize(LastPurchaseDate = max(order_purchase_timestamp, na.rm = TRUE)) %>%
  mutate(Recency = as.numeric(difftime(most_recent_purchase, LastPurchaseDate, units = "days")))

# View the first few rows
head(recency_df)


```

```{r}
# Cacl Frequency
library(dplyr)

frequency_df = RFM_DF %>%
  group_by(customer_unique_id) %>%
  summarize(Frequency = n_distinct(order_id))

summary(frequency_df)
```

```{r}
# Calc Monetary

monetary_df = RFM_DF %>%
  group_by(customer_unique_id) %>%
  summarize(Monetary = sum(payment_value, na.rm = TRUE))

summary(monetary_df)
  
  
```

```{r}
# Combine R,F & M DFs 
rfm = recency_df %>%
  left_join(frequency_df, by = "customer_unique_id") %>%
  left_join(monetary_df, by = "customer_unique_id")

head(rfm)

```

```{r}
# Score customers based on quintiles

rfm = rfm %>%
  mutate(RecencyScore = ntile(Recency, 5),
         FrequencyScore = ntile(Frequency, 5),
         MonetaryScore = ntile(Monetary, 5))

# Invert recency score so most recent have highest score
rfm$RecencyScore = 6 - rfm$RecencyScore

head(rfm)

```
```{r}
# Calculate unweighted average RFM score per customer

customer_RFM_filtered = rfm %>%
  select(customer_unique_id, RecencyScore, FrequencyScore, MonetaryScore)

customer_RFM_filtered$RFM_avg = (customer_RFM_filtered$RecencyScore + customer_RFM_filtered$FrequencyScore + customer_RFM_filtered$MonetaryScore) / 3

final_cust_RFM = customer_RFM_filtered %>%
  select(-RecencyScore, -FrequencyScore, -MonetaryScore)
```


```{r}
write.csv(ord_cust_pay_geo, "ord_cust_pay_geo.csv")
```

```{r}
# Now start calculating features for correlation to RFM score
# Starting with total spend per customer
total_spend = ord_cust_pay_geo %>%
  group_by(customer_unique_id) %>%
  summarize(total_spend = sum(payment_value))

# Orders per customer
num_orders = ord_cust_pay_geo %>%
  group_by(customer_unique_id) %>%
  summarize(num_orders = n_distinct(order_id))

# AOV per customer
aov_cust = total_spend %>%
  left_join(num_orders, by = "customer_unique_id") %>%
  mutate(aov = total_spend / num_orders)


str(total_spend)
```

```{r}
# Calculate avg installments per cust

ord_cust = left_join(orders, customers, by = "customer_id")

ord_cust_pay = left_join(ord_cust, order_payments, by = "order_id")

installments_per_cust = ord_cust_pay %>%
  group_by(customer_unique_id) %>%
  summarize(avg_installments = mean(payment_installments))

str(installments_per_cust)

```

```{r}
# Calculate payment types used by customer

payment_types_cust = ord_cust_pay %>%
  group_by(customer_unique_id) %>%
  summarize(distinct_pay_types = toString(unique(payment_type)))

str(payment_types_cust)
  
```

```{r}
# Add categorical features of customer zip, city and state
library(stringr)

ord_cust_pay = ord_cust_pay %>%
  arrange(customer_unique_id, desc(order_purchase_timestamp)) %>%
  group_by(customer_unique_id) %>%
  slice(1) %>%
  ungroup() %>%
  
  mutate(customer_zip_code_prefix = str_pad(customer_zip_code_prefix, width = 5, side = "left", pad = "0"),
         customer_zip_code_prefix = as.factor(customer_zip_code_prefix),
         customer_city = as.factor(customer_city),
         customer_state = as.factor(customer_state)
  )

# ord_cust_pay = ord_cust_pay %>%
#   select(-custoomer_state)
```

```{r}
# Calculate product categories purchased per customer
# First need to add cat name in English

ord_cust_pay_geo_prod_cat = left_join( ord_cust_pay_geo_prod, cat_name_translation, by = "product_category_name")

cats_per_cust = ord_cust_pay_geo_prod_cat %>%
  group_by(customer_unique_id) %>%
  summarise(distinct_cats = toString(unique(product_category_name_english)))

```

```{r}
# now calc reviews features

# first add reviews data to ord_cust
ord_cust_rev = left_join(ord_cust, order_reviews, by = "order_id")

# Calc reviews per customer
reviews_per_cust = ord_cust_rev %>%
  group_by(customer_unique_id) %>%
  summarise(reviews_per_customer = n_distinct(review_id))

summary(reviews_per_cust)

# Avg review score per customer
review_score_per_cust = ord_cust_rev %>%
  group_by(customer_unique_id) %>%
  summarise(avg_review_score_per_customer = mean(review_score))

summary(review_score_per_cust)

```

```{r}
# Order Timing Per Customer 

# First get year, month and day

library(dplyr)
library(ggplot2)

# Load the orders data
orders = read.csv("../data/olist_orders_dataset.csv")

# Convert order timestamp to datetime 
orders$order_purchase_timestamp = as.POSIXct(orders$order_purchase_timestamp, format = "%Y-%m-%d %H:%M:%S")

# Extract year, month and weekday
orders$year = format(orders$order_purchase_timestamp, "%Y")
orders$month = format(orders$order_purchase_timestamp, "%m")
orders$weekday = weekdays(orders$order_purchase_timestamp)

# Convert weekday to a factor 
orders$weekday = factor(orders$weekday, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

# Rename
orders_with_timing = orders

# Join customers to orders_with_timing

ordtime_cust = left_join(orders_with_timing, customers, by = "customer_id")

head(ordtime_cust)

# Create features for most common order weekday and order month

most_common_weekday = ordtime_cust %>%
  group_by(customer_unique_id, weekday) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(customer_unique_id, desc(count)) %>%
  group_by(customer_unique_id) %>%
  slice(1) %>%
  ungroup() %>%
  select(customer_unique_id, most_common_weekday = weekday)

most_common_month = ordtime_cust %>%
  group_by(customer_unique_id, month) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(customer_unique_id, desc(count)) %>%
  group_by(customer_unique_id) %>%
  slice(1) %>%
  ungroup() %>%
  select(customer_unique_id, most_common_month = month)

head(most_common_month)
```
```{r}
# Calc customer zip code per capita income

# First load data

library(geobr)
library(censobr)
tracts = read_census_tract(code_tract = "all", year=2010)

tract_basico <- read_tracts(year = 2010,
                            dataset = "Basico", 
                            showProgress = FALSE)

tract_income <- read_tracts(year = 2010,
                            dataset = "DomicilioRenda", 
                            showProgress = FALSE)

# select columns
tract_basico <- tract_basico |> select('code_tract','V002')
tract_income <- tract_income |> select('code_tract','V003')

# merge
tracts_df <- left_join(tract_basico, tract_income) |> collect()

# calculate income per capita
tracts_df <- tracts_df |> mutate(income_pc = V003 / V002)
head(tracts_df)

# Merge tracts with tracts_df

tracts_pop_income = left_join(tracts, tracts_df, by = "code_tract")
head(tracts_pop_income)

```

```{r}
# Map lat lng to tracts

# Convert full_df locations into spatial objects

library(dplyr)
library(sf)

# filter out na rows for customer and seller lon/lat

customer_locations = ord_cust_pay_geo %>%
  filter(!is.na(geolocation_lat) & !is.na(geolocation_lng)) %>%
  st_as_sf(coords = c("geolocation_lng", "geolocation_lat"), crs = 4326)

st_crs(customer_locations)
st_crs(tracts)

# Transform geolocations to matching formats
customer_locations = st_transform(customer_locations, crs = 4674)

# Remove any errors
tracts = st_make_valid((tracts))

# Join tracts with locations
customer_tracts = st_join(customer_locations, tracts)

# Join customer_tracts with tracts_df to get income, pop and income pc

customer_tracts_incomepc = left_join(customer_tracts, tracts_df, by = "code_tract")

customer_tracts_incomepc <- as.data.frame(customer_tracts_incomepc)

customer_incomepc = customer_tracts_incomepc %>%
  group_by(customer_unique_id) %>%  
  summarise(mean(income_pc))

# Also get urban or rural 

# Create a subset with only necessary columns
df_subset <- select(customer_tracts_incomepc, customer_unique_id, zone)

# Convert customer_unique_id to a factor if it's currently a string
df_subset$customer_unique_id <- as.factor(df_subset$customer_unique_id)

if ("sf" %in% class(df_subset)) {
  df_subset <- st_set_geometry(df_subset, NULL)
}

# Now convert df_subset to a regular dataframe
df_subset <- as.data.frame(df_subset)

# Convert sf object to a regular dataframe
df_subset <- as.data.frame(df_subset)

# Check if any customer moved from urban to rural or visa versa
customer_zone_count = df_subset %>%
  group_by(customer_unique_id) %>%
  summarize(zone_types = n_distinct(zone), .groups = "drop") %>%
  filter(zone_types > 1)

str(customer_zone_count)

cust_zone_feature = df_subset %>%
  group_by(customer_unique_id) %>%
  summarise(urban_rural = first(zone))


```

```{r}
# Combine all features into one table

library(tidyr)

full_cust_features = customers %>%
  left_join(total_spend, by = "customer_unique_id") %>%
  left_join(num_orders, by = "customer_unique_id") %>%
  left_join(aov_cust, by = "customer_unique_id") %>%
  left_join(installments_per_cust, by = "customer_unique_id") %>%
  # left_join(payment_types_cust, by = "customer_unique_id") %>%
  # left_join(cats_per_cust, by = "customer_unique_id") %>%
  left_join(reviews_per_cust, by = "customer_unique_id") %>%
  left_join(review_score_per_cust, by = "customer_unique_id") %>%
  left_join(most_common_weekday, by = "customer_unique_id") %>%
  left_join(most_common_month, by = "customer_unique_id") %>%
  left_join(customer_incomepc, by = "customer_unique_id") %>%
  left_join(cust_zone_feature, by = "customer_unique_id") 


# Adjust features for ML
full_cust_features$customer_zip_code_prefix = sprintf("%05d", as.integer(full_cust_features$customer_zip_code_prefix))
full_cust_features$customer_zip_code_prefix = as.factor(full_cust_features$customer_zip_code_prefix)
full_cust_features$customer_city = as.factor(full_cust_features$customer_city)
full_cust_features$customer_state = as.factor(full_cust_features$customer_state)
full_cust_features$most_common_month = as.factor(full_cust_features$most_common_month)
full_cust_features$most_common_weekday = as.factor(full_cust_features$most_common_weekday)
full_cust_features$urban_rural = as.factor(full_cust_features$urban_rural)

# One-hot encode features with multiple items

payment_types_expanded = payment_types_cust %>%
  separate_rows(distinct_pay_types, sep = ",\\s*")

pay_types_onehot = payment_types_expanded %>%
  mutate(value = 1) %>%
  pivot_wider(names_from = distinct_pay_types,
              values_from = value,
              values_fill = list(value = 0),
              names_prefix = "paytype_")

full_cust_features = full_cust_features %>%
  left_join(pay_types_onehot, by = "customer_unique_id")

cats_per_cust_expanded = cats_per_cust %>%
  separate_rows(distinct_cats, sep = ",\\s*")

cust_cats_onehot = cats_per_cust_expanded %>%
  mutate(value = 1) %>%
  pivot_wider(names_from = distinct_cats,
              values_from = value,
              values_fill = list(value = 0),
              names_prefix = "prodcat_")

full_cust_features = full_cust_features %>%
  left_join(cust_cats_onehot, by = "customer_unique_id")

full_cust_features = full_cust_features %>%
  select(-customer_id)

full_cust_features = full_cust_features %>%
  select(-paytype_NA)

str(full_cust_features)
  
```
```{r}
# Check for duplicates
full_cust_features_dupes = full_cust_features %>%
  group_by(customer_unique_id) %>%
  filter(n() > 1) %>%
  arrange(customer_unique_id)

library(dplyr)
library(tidyr)


# Identify the duplicated customer_unique_ids
duplicated_ids <- full_cust_features_dupes %>%
  filter(duplicated(customer_unique_id) | duplicated(customer_unique_id, fromLast = TRUE))

# Sort by customer_unique_id to make comparison easier
duplicated_ids_sorted <- duplicated_ids %>%
  arrange(customer_unique_id)

library(data.table)
full_dupes = setDT(duplicated_ids_sorted)[,list(Count = .N), names(duplicated_ids_sorted)]

write.csv(full_dupes, "full_row_dupes.csv")

```

```{r}
# Removing 250 duplicate customer unique ids that I can't explain

duplicate_ids = c("004b45ec5c64187465168251cd1c9c2f", 
"0058f300f57d7b93c477a131a59b36c3", 
"012452d40dafae4df401bced74cdb490", 
"0178b244a5c281fb2ade54038dd4b161", 
"018b5a7502c30eb5f230f1b4eb23a156", 
"031ea691b99fc101dcad357d1a83573f", 
"0451ef5a31cea3e14ce02d768d7c9943", 
"08fb46d35bb3ab4037202c23592d1259", 
"09d74edf20acb4f9523fb1cf19a18456", 
"0ceb502fc33a2ad327b08288c5310e2e", 
"0ea353565cdde00e1d8352a08290a352", 
"10b58cbd6607267fd41812614367439e", 
"1197ba886110324a1519fff17dd8d1d2", 
"11b47516f8f6a42105b9807903ede333", 
"1291474366a550ebc251d9187e763d62", 
"133e20311ec257bda38f1798250d38c5", 
"13473af264dea0facd893d6516900b22", 
"1372bab98f9966bcd4a6fa3e6df6dde8", 
"13abc50b97af7425b5066e405d7cd760", 
"15d2493aa522c1040d639aa74bd1fb31", 
"16bd767d18bf82bb09fc51520f7ea5ab", 
"18186af785c301b05127a291eac901e1", 
"18d61a27f478cd6201df948578f814f9", 
"1a2ede4e787ad199c46719ecb02d81ea", 
"1e0926e360000226b237bf277aec3380", 
"1f90117a847636892e3c5bf569f2ac68", 
"2410195f6521688005612363835a2671", 
"247e0dcd20596bee51bd2b07f633fa04", 
"251e658613a224723f8a077946183b20", 
"280c34dc057ff9f3cd17360673d4b87c", 
"282d49fddab8e95a8673a2a90072cf5c", 
"29f8e372b3b1d42ad2e00a0b976bfc34", 
"2b174670dbec666bbc68b6e2a4062740", 
"2b19910e856b2ba3e7257e63a093a3df", 
"2b952792a20f6076f6e7a9c6a27ade02", 
"2be5dce8b491a7bc6a65d6e91bf49812", 
"2c45ab66a3dae52960147e76a35740ff", 
"2c6a91479a7dc00d8c9d650d8dee88ca", 
"2ccc5d0620e07e3b54b83848c31a08fa", 
"2dd7f52683f631651a5d94056935e1e1", 
"2e08911037fe7ec67377711eee1fdbf3", 
"2f1ae2ed6bbc4661d04c271560570c54", 
"2fd07dc5dbae616986e00fb72e7a779b", 
"313febe2adc914a7cb3f6e903f8e13cf", 
"31bfa97f1ea0663a50ebc5c811ebdf4d", 
"31d958dffbf0b744375b5ff0393e6fb3", 
"330fdaa06f93c0c6ffb4af7d79c1ef12", 
"340d924858c395848c127b3e772b6bfd", 
"345759b8cb3d30586551de1ca6905df0", 
"36cfec707344b75d20e6c7ef583c3b8c", 
"37266d5c6bf5cb0700372d16599a9b21", 
"374fcbbfcf189ae177b2f955f9e74b3d", 
"3c5e1130694632f44051b23fd86ad9e2", 
"3d75cbf8643a1c15723adb850fb5f928", 
"3e43e6105506432c953e165fb2acf44c", 
"3edcab192482e9871c17b34cf98c3996", 
"3f1ae9854823f7c0a8027bd994b2ce64", 
"408aee96c75632a92e5079eee61da399", 
"44b6bbfea26596437062a38c8e6bcec1", 
"4577881f7a6c10d8eb6bd7f7a82ffa86", 
"46b061196b47dfe9318d38bab6a40ee7", 
"47c1a3033b8b77b3ab6e109eb4d5fdf3", 
"4962136f755981b83b03f476e66eea7d", 
"4b1141303289a23d05776bd25076c2fd", 
"4be8154b42b4593fae17f1b2cb375615", 
"4bf3d072dcf303280e82dc697b516c6f", 
"4c93744516667ad3b8f1fb645a3116a4", 
"4cfa5155cf7cff8eb15e0b12041d058e", 
"4e1cce07cd5937c69dacac3c8b13d965", 
"4e5aba2c9b150920c8c7b5b4ee0c197d", 
"4ef6c02126b21225e011b242f9f79c6f", 
"507dc9becd4fc65635d90682dfa9d3a3", 
"508cae50c5c1e72079d266a513bca9ae", 
"50915df398391da01c01bd5cf272f61b", 
"50ad9fb3ba7f8cf336529fe94a182996", 
"50e1b12ee1e2eab6157d9c0b035136af", 
"518199e5f36305bffce18e38aa2642aa", 
"5192c897072033288df55bd01b0e5737", 
"51d8d985d769925b981b4a34ddf6dfc6", 
"5275b2f97b9c995d3d05a58610c0bb67", 
"527c6fbbe85cdf78ff1645e0a71e266f", 
"547d0504ca415eb4864fa3030f73d3f3", 
"5568fb2b583235812ed08eb9587d0465", 
"556ffcdd6185be1c44ea83be3b1b5f86", 
"570eb70ff97166b85ea96be3bfb65fef", 
"58498d9dec038f925f6406ebdfdc36bb", 
"597e54e653cbc1ce5df1e6d97bbc448c", 
"5ad84888519e10ff52d8af00641d41bc", 
"5cbfdb85ec130898108b32c50d619c39", 
"5d2dfd15300a557c1ddfad56a8460226", 
"628bdd93abd27fbdd50f4e2e91ec64b3", 
"62a25a159f9fd2ab7c882d9407f49aa9", 
"6345e3b3ba5ee47685e29ec5febc8155", 
"63669b3731dcc014feec668c3d888aa0", 
"657dec397f46d84dbe64df2b0389b3cc", 
"67806996190d3af60247f64e1d03877f", 
"67bddde1844b238fe25995cde1612b4e", 
"684fdd89d877968793cfb9c8f7ef7874", 
"68f412bbb674141ab49ef13b501baf45", 
"69aab61687fa416ef601af332bd0ff0d", 
"6aa14366984bcc5f1ea760928283d451", 
"6bb0bebc0758e1a834cb5bf96b6d8feb", 
"6d3d5771a12f5e7d00729f940bb28fd2", 
"6e1550b8966f327f29bc06b18972dbec", 
"70aa9ef908248a2ec9e03b77ce1ff357", 
"71048f40f553973d48d6fe35d01a3afb", 
"719f18245d86356b20dbfc6ebff6498d", 
"71b8dc9ce21a7ca5344bde166e117c9f", 
"7311b47a208b4f5af09ccc62fafea9e2", 
"738ffcf1017b584e9d2684b36e07469c", 
"75e750a6279d55f7137bb9e9bb8662cf", 
"78fcceb499ec9008fcecbaad21efefc6", 
"7a6b4947e01039432cac229435d058ee", 
"7b662d846265cb0ed144db95fe0c74dc", 
"7bf1c59401206e31a78523077f3a1144", 
"7bf5c9596fc39d41078cb46a86b23831", 
"7d3d94b4740895a17760e976797f9f0e", 
"7f50c43baa66aae590aa1a067427cce5", 
"801512ead4c9cbc98ecd208f45c975ec", 
"80e00a7b9ead7590bf05116f0237c896", 
"818a54422350b38d3fb1cb3a1553889f", 
"81ede855f58f99b76014d66d161e7a23", 
"82c173abf4679049bd8628bfe89a9f2c", 
"860f75391be5698f015d3b234e7576d6", 
"86b59358310b208f822e416e59c96672", 
"878d1683076172a5b7ffc7126ba99acd", 
"87a7c3090f96d9da963125a0d7f8193a", 
"8b433c0e7b7d2a1f1148b4277cc673f8", 
"8b4bb71a7d37d4c2560e0f0409a58905", 
"8c21dd8c37144807c601f99f2a209dfb", 
"8e84222ad36cb6ab528b745ae6e18d11", 
"8f2fa110f45a5b5592f1593842b7e87d", 
"8f567321ba12101dedc07c70b7021069", 
"8f6ce2295bdbec03cd50e34b4bd7ba0a", 
"91def939002d33dcbf6a038b5c879f7b", 
"9202421110f6a19ddcf0b9b93602a0a1", 
"925751a747a151a7fa97f2f686d028c3", 
"9627e55290c60f562fa06f399ec6b82f", 
"969e62a47aec03c735127e6f11ad6564", 
"9735b1a02ad4d2b3747e9a74cad789a1", 
"97981245c3257ea9b14befffd560177b", 
"97f0fce3f9d7aad1b12499a4e4b10d07", 
"9832ae2f7d3e5fa4c7a1a06e9551bc61", 
"9935b7e2683de890a208026f020e54d3", 
"9af2c271654a36a48beefe342ba6208a", 
"9b7fcde05dd369caf4dea1f04ed39fcc", 
"9b8180cd4fe75a8acd576d0408ff8bf4", 
"9ca25c67e315e2a59b00eca2d4797734", 
"9d1773d6d4fb3faaf3173924d181952a", 
"9f67aa18a87ea9a76854deeb9385c011", 
"a0ef77ac3d3662b055dc12b045da37ed", 
"a262442e3ab89611b44877c7aaf77468", 
"a2eb3545fdbc2c6687e8d66c78c206d6", 
"a43931660f8bbcc1c64db8ddf4b10dff", 
"a4e71a98a7a1490fff07e7a65cf06be2", 
"a53c5bbb7be8b7a0f586d31c2bc499ef", 
"a5bdd83dc32225fadcedd741693cede2", 
"a66315c850c3712707754c1eca7a8069", 
"a6ea57f856565adf869941339028fa05", 
"a9e070f61d35aa13e420c8597b5ccb3d", 
"abc9e5b32caf6ec0c8fa356117b66d66", 
"ac2606825161d003acfbe4f43af273b1", 
"ac3dcee918e6c96eb2ab467158143697", 
"acaf5177d6de60fda7ce77c48abb5230", 
"ad97668eed5826a5d800b15351bea269", 
"ae0ef1d2e3a62b54a83dadad4db14f5d", 
"ae44510fbe1ff7826298182f9f21aee9", 
"b079e8a1977edd900b4522be9dec0245", 
"b0f47d39f0e55621071ec1e93ca6b74d", 
"b17ed96ffdf66518b4cf65e328298e7b", 
"b25a21b56a2d74da49e04cadbc9e0dd8", 
"b26fa76ddf33e534491e4ec46f51bc64", 
"b3a6549b3cd47a7117094faafce8b10d", 
"b495d807ccbd38ea1be486a826c88008", 
"b531620286c6c6fbd1d3e7b58390fec0", 
"b643c19d91a65d73f94ba8e037668986", 
"b9544dcc09004b3b28e388ed130e50f1", 
"b9badb100ff8ecc16a403111209e3a06", 
"baffecbd1fcc31f8a415cef1cd8cf772", 
"bc7b9e0d078c0c01f622b38cfcd7ee9c", 
"bcc9a08b533971412be737fd5bd918b3", 
"bd8e0f3ea9fb694fc53c7a358643fc06", 
"bf448042b40749d8b95fe00c08a9b5cb", 
"bf6656ef50e6fd00e7517b01d615b4f3", 
"bfb33fedf91eb21f6d32ad5345989a6e", 
"c0ceb197de4a31388883a6369ec291d6", 
"c17526359e1068290ebf7dd22a856de7", 
"c1977e8e3ea0900e70cd1dd70123d382", 
"c25d2fb6d22e04ce43c3652e3cacadad", 
"c2919fbdb45366551c1e80d5cb35cd3f", 
"c45ece361aab055ea6c55b61eb2d99c0", 
"c4cf9b10d2668bfabb498d93004ab4a0", 
"c51a1ea9fa9851c70f89d1178c861150", 
"c5cc0bee4b73138ed973a1720df085aa", 
"c7819760e70376028f519e3b57e6c441", 
"c9b3b24308b1a4587ffa3e60fafc2b1f", 
"ca994abc57b0bd7981d91d0061b3d8d6", 
"cbebce165db72a2bfba9e81a3411bdf7", 
"cc44d1f72587f44e3af25f68f1db8cd2", 
"cdc8b0d152b868db7e28de59f642c94a", 
"ce41a50f9ff95ef577cb759483fe9165", 
"d0401aa66d5c33ae752ece32f8474d3c", 
"d052fe86655dae0e952c1bacbbb99d7a", 
"d0f6a442ee95ea8674c2d8ba325f41c0", 
"d130666a33d3681209c5c752fe56ee10", 
"d16f2966cda34d01f661bfc50635edb2", 
"d27295915d486516b99c3aed8628e83b", 
"d3f15df5924e63131bcdac6364b6a6fd", 
"d44ccec15f5f86d14d6a2cfa67da1975", 
"d4a5e9f19897de65433c9d97bf4b9f8e", 
"d55417a83a73d1702b43988e63f0731a", 
"d5f79f616536f08c3946ee6ac810a43a", 
"d970a2354b55cfb67fa5840b9b4936ed", 
"da5bbfd583efb762f6fda762f1aaf4a9", 
"dc80a79483121fee90b0d2f53d1054f5", 
"dcd27efb93b723b301f8bac00e5d7e01", 
"dce6dc77c19d239bfbe9d77dd4d0ef98", 
"e0233c751408137ec5cdde0c37e6a61a", 
"e14b8cd578c1f576594719bce2ee1aa2", 
"e219a439f6ca99e32824bcc7153969c9", 
"e325e139452a1ca05f5a33acedd7d94f", 
"e35b2a3c980b6e0fc66c66b8e1122e93", 
"e4971a4defaf07a1d7f2ff615a32c809", 
"e53821a413d5b137cd9005b41f09dfe0", 
"e60856952187516c3397a2c4ac63aac4", 
"e7688fef5438be571d0c39bbb3e8e998", 
"e836a4279bd9127752d8949d46f7a5a5", 
"e8663abca66edfe7b18d03a921637578", 
"eac6dbc8ecd0a2f08ed8e53d18f0e0d0", 
"eb89ecac165940c95a05cb77e89a789d", 
"ec0f5b4fe392d71f361112c1b508b707", 
"ec6a85d8bf9c7a514c411a1287643d1d", 
"ed91e2bcbc71d72c1d7871961a01d3e3", 
"edb73fb9e9c6e283badde40e37f5c9e5", 
"eddc1407b097ef7952deb24806c9059b", 
"ee4a5dab94b427525ea24bc30d4442fb", 
"efce1ab3e96ccab8b1b464326bd22417", 
"f00aa1cfc257dfff20184269b19db923", 
"f113042ff356f926d517f3087d4a1ba8", 
"f145d50379275ab9931636f83b0102eb", 
"f216de65ece42736f341247dcba60ccb", 
"f34cd7fd85a1f8baff886edf09567be3", 
"f7471d502dd946e0a2cb6020bf076808", 
"f7b62c75467e8ce080b201667cbbc274", 
"f80c7e4cf2fa8ff3532323f19bf603ba", 
"f8c74f26f568c1b52cd212e700e977df", 
"f92fd2c87375f957ece022972b16849b", 
"f95de29d9e810e69f55626ff1bbd4d60", 
"fb490a070c5dbc385afadcf0e56270bd", 
"fd09c64a101e3eff4adbca1b28552514", 
"fe3e52de024b82706717c38c8e183084", 
"fe59d5878cd80080edbd29b5a0a4e1cf" 
)

full_cust_features = full_cust_features %>%
  filter(!(customer_unique_id %in% duplicate_ids))

saveRDS(full_cust_features, "full_cust_features_exdupes")
```

```{r}

# Check out missing values to decide what to do with them

# Summarize for each column
missing_vals = sapply(full_cust_features, function(x) sum(is.na(x)))
print(missing_vals)

# Filter for rows with NAs

rows_with_na = full_cust_features[!complete.cases(full_cust_features),]

# Main missing vals in income_pc and urban_rural so check if those are repeated zip codes 

# Rename mean(income_pc)

full_cust_features = full_cust_features %>%
  rename(mean_income_pc = 'mean(income_pc)')

# Check if missing income and zone data is for every row of a given zip code prefix

# Calculate aggregated values for each zip_code_prefix
zip_code_aggregates <- full_cust_features %>%
  group_by(customer_zip_code_prefix) %>%
  summarize(
    avg_mean_income_pc = mean(mean_income_pc, na.rm = TRUE),
    common_urban_rural = first(urban_rural)  # Assuming Mode is a function you have to define to find the most common value
  )
# Joining the aggregated values
full_cust_features<- full_cust_features %>%
  left_join(zip_code_aggregates, by = "customer_zip_code_prefix")

# Impute missing values
full_cust_features <- full_cust_features %>%
  mutate(
    mean_income_pc = ifelse(is.na(mean_income_pc), avg_mean_income_pc, mean_income_pc),
    urban_rural = ifelse(is.na(urban_rural), common_urban_rural, urban_rural)
  )

full_cust_features <- full_cust_features %>%
  select(-avg_mean_income_pc, -common_urban_rural)

# Check NAs again

missing_vals = sapply(full_cust_features, function(x) sum(is.na(x)))
print(missing_vals)

# Decided to delete NAs since they are a small proportion of the records

full_cust_features_cleaned = na.omit(full_cust_features)

```

```{r}
# Remove duplicated cols

# confirm duplicated cols

total_spend_identical = identical(full_cust_features_cleaned$total_spend.x, full_cust_features_cleaned$total_spend.y)

num_orders_identical = identical(full_cust_features_cleaned$num_orders.x, full_cust_features_cleaned$num_orders.y)

print(total_spend_identical)
print(num_orders_identical)

# Remove duplicated cols and rename columns

full_cust_features_cleaned = full_cust_features_cleaned %>%
  select(-total_spend.y, -num_orders.y)

names(full_cust_features_cleaned)[names(full_cust_features_cleaned) == "total_spend.x"] = "total_spend"
names(full_cust_features_cleaned)[names(full_cust_features_cleaned) == "num_orders.x"] = "num_orders"
```

```{r}
# Add RFM scores to full_cust_features_cleaned and create final_analysis_df

final_analysis_df = left_join(full_cust_features_cleaned, final_cust_RFM, by = "customer_unique_id")

```


```{r}
# Need to convert numeric data to sparse matrix to make dataset manageable size
library(Matrix)
library(dplyr)

final_analysis_numeric = final_analysis_df %>% select_if(is.numeric)

final_analysis_numeric_exRFM = final_analysis_numeric %>%
  select(-RFM_avg)

sparse_analysis_df = Matrix(as.matrix(final_analysis_numeric), sparse = TRUE)

```


```{r}
# Set up data to run LASSO and Ridge Regression for Dimensionality Reduction

library(caret)
library(glmnet)


# Standardize the numeric features

# Calc mean and stdev

means = apply(final_analysis_numeric, 2, mean, na.rm = TRUE)
sds = apply(final_analysis_numeric, 2, sd, na.rm = TRUE)

# Standardize the sparse matrix

sparse_analysis_df = as(sparse_analysis_df, "dgCMatrix")

for(i in 1:ncol(sparse_analysis_df)) {
  sparse_analysis_df[,i] = (sparse_analysis_df[,i] - means[i]) / sds[i]
}

summary(sparse_analysis_df)

```

```{r}
# Run LASSO

response_var = final_analysis_df$RFM_avg

response_var = as.vector(response_var)

cv_lasso = cv.glmnet(sparse_analysis_df, response_var, alpha = 1)

cv_ridge = cv.glmnet(sparse_analysis_df, response_var, alpha = 0)

# Extract best lambda value


best_lambda_lasso = cv_lasso$lambda.min
best_lambda_ridge = cv_ridge$lambda.min

# Extract coefficients of best lambdas

coef_lasso = coef(cv_lasso, s = "lambda.min")
coef_ridge = coef(cv_ridge, s = "lambda.min")

#Print coefficients

print(coef_lasso)
print(coef_ridge)

# Plot the cross-validation error
plot(cv_lasso)
plot(cv_ridge)

# More detailed look at coefficients
coef_lasso_df = as.data.frame(coef_lasso)
coef_ridge_df = as.data.frame(coef_ridge)

write.csv(coef_lasso_df, "coef_lasso_df.csv")
write.csv(coef_ridge_df, "coef_ridge_df.csv")

```

```{r}

# Convert dgCMatrix to regular matrix
regular_matrix <- as.matrix(sparse_analysis_df)

# Get coefficients for LASSO at the best lambda
lasso_coefs <- predict(cv_lasso, s = "lambda.min", type = "coefficients")

# Coefficients are returned as a list, convert to a named vector
lasso_coefs_vector <- as.vector(lasso_coefs[[1]])

# Create a data frame of feature names and their corresponding coefficients
feature_names <- row.names(lasso_coefs)
lasso_coefs_df <- data.frame(Feature = feature_names, Coefficient = lasso_coefs_vector)

# Do the same for Ridge Regression
ridge_coefs <- predict(cv_ridge, s = "lambda.min", type = "coefficients")
ridge_coefs_vector <- as.vector(ridge_coefs[[1]])
ridge_coefs_df <- data.frame(Feature = feature_names, Coefficient = ridge_coefs_vector)

# View the first few rows of the data frames
head(lasso_coefs_df)
head(ridge_coefs_df)


```

