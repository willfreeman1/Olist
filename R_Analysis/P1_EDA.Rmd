```{r}
# Initial EDA of Olist Dataset (after creating major dataframes)
```


```{r}
# Starting with Revenue EDA
# R1 - Revenue over time


library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyr)

getwd()

order_payments = read.csv("../data/olist_order_payments_dataset.csv")

delivered_orders = orders %>%
  filter(order_status == "delivered")

delivered_orders_payments = delivered_orders %>%
  left_join(order_payments, by = "order_id")

R1_rev_prep = delivered_orders_payments %>%
  group_by(order_id) %>%
  summarise(revenue = sum(payment_value), order_purchase_timestamp = first(order_purchase_timestamp))

R1_rev_prep$order_purchase_timestamp = as.Date(R1_rev_prep$order_purchase_timestamp)

R1_rev_prep_monthly = R1_rev_prep %>%
  mutate(
    year = year(order_purchase_timestamp),
    month = month(order_purchase_timestamp)
  )

R1_rev_monthly = R1_rev_prep_monthly %>%
  group_by(year, month) %>%
  summarise(monthly_revenue = sum(revenue))

R1_rev_monthly$date = as.Date(paste(R1_rev_monthly$year, sprintf("%02d", R1_rev_monthly$month), "1", sep = "-"))

format_brl = function(x){
  paste("R$", formatC(x, format = "f", big.mark = ".", decimal.mark = ",", digits = 2))
}

# Plot R1 Total Revenue over Time
ggplot(R1_rev_monthly, aes(x = date, y = monthly_revenue)) +
  geom_line() +
  geom_point() +
  theme_minimal()+
  labs(title = "Total Monthly Revenue (Delivered Orders)", x = "Date", y = "Total Revenue" ) +
  scale_y_continuous(labels = format_brl) +
  theme(axis.text = element_text(angle = 45, hjust = 1))

monthly_data = R1_rev_prep_monthly %>%
  group_by(year,month) %>%
  summarise(
    total_revenue = sum(revenue),
    total_orders = n(),
    aov = total_revenue / total_orders
  )
monthly_data$date = as.Date(paste(monthly_data$year, sprintf("%02d", monthly_data$month), "1", sep = "-"))


# Scale factor for the secondary axis
monthly_data_plot = monthly_data %>%
  filter(date >= as.Date("2017-01-01") & date <= as.Date("2018-09-01"))

scale_factor <- max(monthly_data_plot$total_orders) / max(monthly_data_plot$aov)

# Create the plot
p <- ggplot(monthly_data, aes(x = date)) +
  geom_line(aes(y = total_orders, colour = "Total Orders")) +
  geom_line(aes(y = aov * scale_factor, colour = "AOV")) +
  scale_y_continuous(name = "Total Orders",
                     sec.axis = sec_axis(~ . / scale_factor, name = "AOV")) +
  scale_colour_manual("", values = c("Total Orders" = "blue", "AOV" = "red")) +
  theme_minimal() +
  labs(x = "Date", colour = "Metric") +
  theme(axis.text.y.right = element_text(angle = 90),
        axis.title.y.right = element_text(angle = 90))

# Print the plot
print(p)
```

```{r}
# save data for shiny plot

# Ensure the 'date' column exists in 'monthly_data'
monthly_data$date = as.Date(paste(monthly_data$year, sprintf("%02d", monthly_data$month), "1", sep = "-"))

# Filter the data based on your date range
orders_vs_aov <- monthly_data %>%
  filter(date >= as.Date("2017-01-01") & date <= as.Date("2018-09-01")) %>%
  select(date, total_orders, aov) # Select the necessary columns

# Save the dataframe as an RDS file
saveRDS(orders_vs_aov, "orders_vs_aov.rds")

```


```{r}
# Calculate and Plot R2: MoM Contribution to Revenue Growth with AOV and Total Orders 

R1_rev__MoM = R1_rev_monthly %>%
  arrange(date) %>%
  mutate(mom_growth = ifelse(is.na(lag(monthly_revenue)) | is.na(monthly_revenue),
                        NA,
                        (monthly_revenue / lag(monthly_revenue) -1) * 100))

monthly_data = R1_rev_prep_monthly %>%
  group_by(year,month) %>%
  summarise(
    total_revenue = sum(revenue),
    total_orders = n(),
    aov = total_revenue / total_orders
  )

monthly_data$date = as.Date(paste(monthly_data$year, sprintf("%02d", monthly_data$month), "1", sep = "-"))

R2_data = merge(monthly_data, R1_rev__MoM[, c("date", "mom_growth")], by = "date")

R2_data = R2_data %>%
  arrange(date) %>%
  mutate(
    aov_growth = (aov / lag(aov) -1) * 100,
    orders_growth = (total_orders / lag(total_orders) - 1) * 100, 
    mom_growth
  )

filtered_R2 = R2_data %>%
  filter(date >= as.Date("2017-02-01"))

# Now transform and plot

long_filtered_R2 = filtered_R2 %>%
  select(date, aov_growth, orders_growth) %>%
  pivot_longer(cols = c(aov_growth, orders_growth), names_to = "category", values_to = "value")

ggplot() +
  geom_line(aes(x = date, y = mom_growth), data = filtered_R2, color = "blue") +
  geom_bar(aes(x = date, y = value, fill = category), data = long_filtered_R2, stat = "identity", position = "stack") +
  scale_fill_manual(values = c("red", "green")) +
  labs(title = "MoM Growth with Contributions from AOV and Total Orders",
       x = "Month",
       y = "Value", 
       fill = "Category") +
  theme_minimal() +
  theme(axis.text = element_text(angle = 45, hjust = 1))
  scale_x_date(date_breaks = "1 month", date_labels = "%b %Y")
  
```
```{r}
# Assuming you have already read the datasets and performed the preliminary filtering as per your code
library(zoo)
library(scales)

# Convert date to a quarter format
R1_rev_monthly$quarter <- as.yearqtr(R1_rev_monthly$date)

# Filter out the data before Q1 2017
R1_rev_quarterly <- R1_rev_monthly %>%
  filter(quarter >= as.yearqtr("2017 Q1"))

# Group data by quarter and calculate the total revenue per quarter
R1_rev_quarterly <- R1_rev_quarterly %>%
  group_by(quarter) %>%
  summarise(quarterly_revenue = sum(monthly_revenue))

# Calculate QoQ growth
R1_rev_quarterly <- R1_rev_quarterly %>%
  mutate(qoq_growth = (quarterly_revenue / lag(quarterly_revenue) - 1) * 100)

print(R1_rev_quarterly)

# Replace NA in the first row of qoq_growth with 0 or remove it
R1_rev_quarterly <- R1_rev_quarterly %>%
  mutate(qoq_growth = ifelse(is.na(qoq_growth), 0, qoq_growth))

print(R1_rev_quarterly)

# Now plot the QoQ revenue growth
ggplot(R1_rev_quarterly, aes(x = quarter, y = qoq_growth)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = "Quarter-on-Quarter Revenue Growth", x = "Quarter", y = "QoQ Growth (%)") +
  # scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Note: The scales package provides the percent formatter for the y-axis.



```
```{r}
library(zoo)
library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)

# Ensure R1_rev_prep_monthly is prepped with 'order_purchase_timestamp' and 'revenue' calculated

# Convert date to a quarter format and calculate quarterly data
R1_rev_prep_quarterly <- R1_rev_prep_monthly %>%
  mutate(quarter = as.yearqtr(order_purchase_timestamp)) %>%
  group_by(quarter) %>%
  summarise(
    total_revenue = sum(revenue),
    total_orders = n(),
    aov = total_revenue / total_orders
  ) %>%
  arrange(quarter) %>%
  filter(quarter >= as.yearqtr("2017 Q1"))  # Filter from Q1 2017

# Calculate QoQ growth for revenue, AOV, and orders
R1_rev_quarterly_growth <- R1_rev_prep_quarterly %>%
  mutate(
    revenue_growth = (total_revenue / lag(total_revenue) - 1) * 100,
    aov_growth = (aov / lag(aov) - 1) * 100,
    orders_growth = (total_orders / lag(total_orders) - 1) * 100
  ) %>%
  # Replace NA with 0 for the first row
  mutate(
    revenue_growth = ifelse(is.na(revenue_growth), 0, revenue_growth),
    aov_contribution = total_revenue / lag(total_revenue) * aov_growth,
    orders_contribution = total_revenue / lag(total_revenue) * orders_growth
  )

# Pivot the contribution data for plotting
contributions <- R1_rev_quarterly_growth %>%
  select(quarter, aov_contribution, orders_contribution) %>%
  pivot_longer(cols = c(aov_contribution, orders_contribution), names_to = "category", values_to = "value")

# Now plot the QoQ revenue growth with contributions
ggplot() +
  geom_line(data = R1_rev_quarterly_growth, aes(x = quarter, y = revenue_growth), color = "blue") +
  geom_bar(data = contributions, aes(x = quarter, y = value, fill = category), stat = "identity", position = "stack") +
  scale_fill_manual(values = c("aov_contribution" = "red", "orders_contribution" = "green")) +
  theme_minimal() +
  labs(title = "Quarter-on-Quarter Revenue Growth with AOV and Orders Contribution",
       x = "Quarter",
       y = "Growth (%)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

```{r}

ts_data_full = read.csv()





```




```{r}
library(prophet)
library(dplyr)
library(ggplot2)

# Filter ts_data_full to only dates with actual revenue data
actual_data <- ts_data_full %>%
  filter(revenue > 0) %>%
  mutate(Model = "Actual")

# Define last date of actual revenue data
last_actual_data_date <- max(actual_data$date)

# Make sure 'date' is in Date format
actual_data <- ts_data_full %>%
  filter(revenue > 0) %>%
  mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
  mutate(Model = "Actual")

actual_data <- ts_data_full %>%
  filter(revenue > 0) %>%
  mutate(ds = as.Date(date)) %>%
  filter(!is.na(ds)) %>%
  mutate(Model = "Actual")

# Now, you can rename 'date' to 'ds' and use it in Prophet
m_prophet <- prophet(actual_data %>% select(ds = date, y = revenue))


# Create a future dataframe for 60 days beyond the last actual revenue date
future_dates <- make_future_dataframe(m_prophet, periods = 60, include_history = FALSE)

# Forecast with Prophet 
forecast_prophet <- predict(m_prophet, future_dates)

# Prep forecast data for plotting
forecast_data <- forecast_prophet %>%
  select(date = ds, Revenue = yhat) %>%
  mutate(Model = "Forecast")

# Combine actual and forecast data for plotting
plot_data <- rbind(
  actual_data %>% select(date, Revenue = revenue, Model),
  forecast_data
)

# Plot 
ggplot(plot_data, aes(x = date, y = Revenue, color = Model)) +
  geom_line() +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  labs(title = "Revenue Forecast for the Next 60 Days",
       x = "Date",
       y = "Revenue",
       color = "Model") +
  theme_minimal()


```

```{r}
# Next I'll look at the number of unique products purchased and number of unique customers purchasing as Unique_Prods_Custs



# Then I want to group by month and count unique products and unique unique_customer_ids
consolidated_orders_customers$order_purchase_timestamp = as.Date(consolidated_orders_customers$order_purchase_timestamp)

cust_orditems_delivered = consolidated_orders_customers%>%
  mutate(month_as_date = floor_date(order_purchase_timestamp, "month"))

unique_prods_custs_monthly = cust_orditems_delivered %>%
  group_by(month_as_date) %>%
  summarise(unique_prods = n_distinct(product_id),
            unique_custs = n_distinct(customer_unique_id)) %>%
  arrange(month_as_date)

unique_prods_custs_monthly = unique_prods_custs_monthly %>%
  filter(month_as_date >= as.Date("2017-01-01") & month_as_date <= as.Date("2018-08-01"))

# Transform & Plot
long_data = unique_prods_custs_monthly %>%
  pivot_longer(
    cols = c(unique_prods, unique_custs),
    names_to = "category",
    values_to = "value"
  )

ggplot(long_data, aes(x = month_as_date, y = value, color = category)) +
  geom_line() +
  labs(title = "Unique Products and Customers By Month",
       x = "Month",
       y = "Count",
       color = "Category") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %Y") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
```

```{r}
# Next for P1 of Dashboard I want to show purchase day of week and time of day histograms

library(ggplot2)
getwd()

orders = read.csv("../data/olist_orders_dataset.csv")

# Make the timestamp a real timestamp
orders$order_purchase_timestamp = as.POSIXct(orders$order_purchase_timestamp, format = "%Y-%m-%d %H:%M:%S")

# Extract day of week

orders$weekday = weekdays(orders$order_purchase_timestamp)

orders$weekday = factor(orders$weekday, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))

# Create table of day counts

day_counts = table(orders$weekday)
print(day_counts)

# Plot DoW Histogram

par(mar=c(7,4,4,2) + 0.1)
daycount_bar = barplot(day_counts, main = "Order Frequency by Day of the Week", ylab = "Frequency", xaxt = "n", col = "blue")
axis(1, at = daycount_bar, labels = names(day_counts), las = 2)
par(mar=c(5, 4, 4, 2) + 0.1)


```

```{r}
# The above is not so intersting. Let's try seeing if the DoW changes over time
library(dplyr)
library(ggplot2)

orders = read.csv("../data/olist_orders_dataset.csv")

orders$order_purchase_timestamp = as.POSIXct(orders$order_purchase_timestamp, format = "%Y-%m-%d %H:%M:%S")


orders$year = format(orders$order_purchase_timestamp, "%Y")
orders$month = format(orders$order_purchase_timestamp, "%m")
orders$weekday = weekdays(orders$order_purchase_timestamp)

orders$weekday = factor(orders$weekday, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))

order_timing = orders %>%
  group_by(year, month, weekday) %>%
  summarize(Frequency = n(), .groups = "drop")

# Calculate each weekday's percent of total orders per month

ords_monthly = order_timing %>%
  group_by(year, month) %>%
  summarize(monthly_orders = sum(Frequency),.groups = "drop")

order_timing_totals = order_timing %>%
  left_join(ords_monthly, by = c("year", "month"))

order_timing_totals = order_timing_totals %>%
  mutate(percentage = (Frequency / monthly_orders) * 100)

# Prep line plot

order_timing_totals$year = as.factor(order_timing_totals$year)
order_timing_totals$month = as.factor(order_timing_totals$month)

order_timing_totals$year_month = paste(order_timing_totals$year,order_timing_totals$month, sep = "-" )

order_timing_totals$year_month = factor(order_timing_totals$year_month)

spread_labels = order_timing_totals$year_month %in% order_timing_totals$year_month[seq(1, nrow(order_timing_totals), by = 12)]

# Plot
ggplot(order_timing_totals, aes(x = year_month, y = percentage, group = weekday, color = weekday)) +
  geom_line() +
  scale_y_continuous(limits = c(0, 35)) +
  scale_x_discrete(breaks = order_timing_totals$year_month[spread_labels]) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.text.x.bottom = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(title = "Percentage of Total Orders by Weekday",
       x = "Date",
       y = "Percent",
       color = "Weekday") +
  theme_minimal()

```


```{r}


```

```{r}
# The DoW over time didn't show much so back to regular all time view for order time of day

# First extract the hour from timestamps

orders$hour = as.numeric(format(orders$order_purchase_timestamp, "%H"))

# Then categorize hours into parts of the day

orders$time_of_day = cut(orders$hour,
                         breaks = c(-Inf, 6, 12, 18, 24),
                         labels = c("Early Morning", "Morning", "Afternoon", "Evening"),
                         right = FALSE)

# Create time of day table

time_of_day_counts = table(orders$time_of_day)

# Plot
par(mar= c(7,4,4,2) + 0.1)
time_of_day_bar = barplot(time_of_day_counts, main = "Order Frequency By Time of Day", ylab = "Frequency", xaxt = "n", col = "blue")
axis(1, at = time_of_day_bar, labels = names(time_of_day_counts), las = 2)
par(mar = c(5,4,4,2) + 0.1)
```

```{r}
saveRDS(orders, "C:\\Users\\willf\\OneDrive\\Documents\\NYDSA\\R\\Olist\\Data\\orders_with_timing.rds" )
```


```{r}
df = ord_cust_pay_geo_prod_cat

# Assuming your dataframe is named df
df <- df %>%
  mutate(
    order_purchase_timestamp = as.Date(order_purchase_timestamp),
    year_month = format(order_purchase_timestamp, "%Y-%m")
  )

# Check a few rows to confirm the transformation
print(head(df))


monthly_revenue <- df %>%
  group_by(year_month, product_category_name_english) %>%
  summarise(monthly_revenue = sum(payment_value * units_ordered), .groups = "drop")

# Check the monthly revenue
print(head(monthly_revenue))


prodcat_share_revenue <- monthly_revenue %>%
  group_by(year_month) %>%
  mutate(total_revenue = sum(monthly_revenue)) %>%
  ungroup() %>%
  mutate(share_of_revenue = (monthly_revenue / total_revenue) * 100)

# Check the share of revenue
print(head(prodcat_share_revenue))


# Filter for relevant months
relevant_months <- prodcat_share_revenue %>%
  filter(year_month %in% c("2017-01", "2018-01", "2018-08"))

# Check the filtered data
print(head(relevant_months))

# Separate the data by year_month
share_2017_01 <- relevant_months %>% filter(year_month == "2017-01")
share_2018_01 <- relevant_months %>% filter(year_month == "2018-01")
share_2018_08 <- relevant_months %>% filter(year_month == "2018-08")

# Calculating changes in share
change_2017_to_2018 <- share_2018_01 %>%
  left_join(share_2017_01, by = "product_category_name_english", suffix = c("_2018", "_2017")) %>%
  mutate(change_2017 = share_of_revenue_2018 - share_of_revenue_2017)

change_2018_Jan_Aug <- share_2018_08 %>%
  left_join(share_2018_01, by = "product_category_name_english", suffix = c("_Aug", "_Jan")) %>%
  mutate(change_2018_Jan_Aug = share_of_revenue_Aug - share_of_revenue_Jan)

# Combine the changes for final output
final_change <- change_2017_to_2018 %>%
  select(product_category_name_english, change_2017) %>%
  left_join(change_2018_Jan_Aug %>% select(product_category_name_english, change_2018_Jan_Aug),
            by = "product_category_name_english")

# Check the final output
print(head(final_change))
write.csv(final_change, "final_change.csv")


```


```{r}
install.packages("RColorBrewer")
```

```{r}
df = ord_cust_pay_geo_prod_cat
library(dplyr)
library(ggplot2)
library(lubridate)
library(forcats)
library(RColorBrewer)

# Assuming your dataframe is named df
# and df$order_purchase_timestamp, df$product_category_name_english, and df$payment_value are available

# Ensure payment_value is numeric
df$payment_value <- as.numeric(df$payment_value)

# Convert order_purchase_timestamp to Date and extract year and month
df <- df %>%
  mutate(
    order_purchase_timestamp = as.Date(order_purchase_timestamp),
    year_month = format(order_purchase_timestamp, "%Y-%m")
  )

# Calculate monthly revenue by category
monthly_revenue_by_category <- df %>%
  group_by(year_month, product_category_name_english) %>%
  summarise(monthly_revenue = sum(payment_value), .groups = "drop")

# Find the top 20 categories by total revenue in 2017
top_categories <- monthly_revenue_by_category %>%
  filter(substr(year_month, 1, 4) == "2017") %>%
  group_by(product_category_name_english) %>%
  summarise(total_revenue = sum(monthly_revenue), .groups = "drop") %>%
  top_n(20, total_revenue) %>%
  arrange(desc(total_revenue)) %>%
  pull(product_category_name_english)

# Add an "Other" category for those not in the top 20
monthly_revenue_by_category <- monthly_revenue_by_category %>%
  mutate(
    category_grouped = if_else(product_category_name_english %in% top_categories,
                               as.character(product_category_name_english), "Other")
  )

# Recalculate monthly revenue by the new grouped category
monthly_revenue_grouped <- monthly_revenue_by_category %>%
  group_by(year_month, category_grouped) %>%
  summarise(monthly_revenue = sum(monthly_revenue), .groups = "drop")

# Assign colors
num_categories <- length(unique(monthly_revenue_grouped$category_grouped))
colors <- brewer.pal(min(num_categories, 9), "Set3") # Using Set3, adjust as necessary
# If num_categories > 9, repeat colors or choose another strategy
if(num_categories > 9) {
  colors <- rep(colors, length.out = num_categories)
}

# Create a named vector of colors
category_order <- unique(monthly_revenue_grouped$category_grouped)
named_colors <- setNames(colors, category_order)

# Add color information to the dataframe
monthly_revenue_grouped <- monthly_revenue_grouped %>%
  mutate(color = named_colors[category_grouped])

# Ensure the entire time period is included
monthly_revenue_grouped <- monthly_revenue_grouped %>%
  filter(year_month >= "2017-01", year_month <= "2018-08")

# Create a vector of distinct colors
num_categories <- length(unique(monthly_revenue_grouped$category_grouped))
colors <- sample(brewer.pal(min(num_categories, 12), "Set3"), num_categories, replace = TRUE)

# Order categories by total revenue in 2017
category_order <- monthly_revenue_grouped %>%
  filter(year_month < "2018-01") %>%
  group_by(category_grouped) %>%
  summarise(total_revenue_2017 = sum(monthly_revenue), .groups = "drop") %>%
  arrange(desc(total_revenue_2017)) %>%
  pull(category_grouped)

monthly_revenue_grouped$category_grouped <- factor(monthly_revenue_grouped$category_grouped, levels = category_order)

# Create the stacked area chart
ggplot(monthly_revenue_grouped, aes(x = as.Date(paste0(year_month, "-01")), y = monthly_revenue, fill = category_grouped)) +
  geom_area(position = 'stack') +
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
  scale_fill_manual(values = setNames(colors, category_order)) +
  labs(title = "Monthly Revenue by Top 20 Product Categories in 2017 and Others",
       x = "Month", y = "Revenue (Stacked by Total Revenue in 2017)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill=guide_legend(title="Product Category"))




```
```{r}
df = ord_cust_pay_geo_prod_cat
library(dplyr)
library(ggplot2)
library(lubridate)
library(forcats)
library(RColorBrewer)

# Convert order_purchase_timestamp to Date and extract year_month
df <- df %>%
  mutate(
    order_purchase_timestamp = as.Date(order_purchase_timestamp),
    year_month = format(order_purchase_timestamp, "%Y-%m"),
    payment_value = as.numeric(payment_value)  # Ensure payment_value is numeric
  )

# Calculate monthly revenue by category
monthly_revenue_by_category <- df %>%
  group_by(year_month, product_category_name_english) %>%
  summarise(monthly_revenue = sum(payment_value), .groups = "drop")

# Identify the top 20 categories based on total revenue in 2017
top_categories <- monthly_revenue_by_category %>%
  filter(year_month >= "2017-01" & year_month <= "2017-12") %>%
  group_by(product_category_name_english) %>%
  summarise(total_revenue_2017 = sum(monthly_revenue), .groups = "drop") %>%
  top_n(20, total_revenue_2017) %>%
  arrange(desc(total_revenue_2017)) %>%
  pull(product_category_name_english)

# Add an "Other" category for those not in the top 20
monthly_revenue_by_category <- monthly_revenue_by_category %>%
  mutate(
    category_grouped = if_else(product_category_name_english %in% top_categories,
                               product_category_name_english, "Other")
  )

# Recalculate monthly revenue, now grouped by the new category_grouped
monthly_revenue_grouped <- monthly_revenue_by_category %>%
  group_by(year_month, category_grouped) %>%
  summarise(monthly_revenue = sum(monthly_revenue), .groups = "drop")

# Assign colors to categories, including "Other"
num_categories <- length(unique(monthly_revenue_grouped$category_grouped))
# Define combined palette
      palette1 <- brewer.pal(8, "Dark2")  # 8 distinct colors
      palette2 <- brewer.pal(8, "Set3")   # Another 8 distinct colors
      palette3 <- brewer.pal(8, "Paired")[1:5]  # Taking only 5 from this to make up 21
      colors <- c(palette1, palette2, palette3)  # Combine them together
      
# If you have more than 8 categories, consider repeating the palette or using another strategy to generate more colors

# Ensure category order is based on total revenue in 2017
monthly_revenue_grouped <- monthly_revenue_grouped %>%
  mutate(category_grouped = factor(category_grouped, levels = c(top_categories, "Other")))

# Plot
ggplot(monthly_revenue_grouped, aes(x = as.Date(paste0(year_month, "-01")), y = monthly_revenue, fill = category_grouped)) +
  geom_area(position = 'stack') +
  scale_fill_manual(values = colors) +
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
  labs(title = "Monthly Revenue by Product Category",
       x = "Month", y = "Revenue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill=guide_legend(title="Product Category"))



```

```{r}

color_mapping <- setNames(colors, levels(monthly_revenue_grouped$category_grouped))

# Add a 'color' column to 'monthly_revenue_grouped' based on 'category_grouped'
monthly_revenue_grouped <- monthly_revenue_grouped %>%
  mutate(color = color_mapping[as.character(category_grouped)])

# Check the structure to ensure 'color' column is added correctly
head(monthly_revenue_grouped)

saveRDS(monthly_revenue_grouped, "monthly_revenue_grouped_with_colors.rds")

```


```{r}
df = ord_cust_pay_geo_prod_cat

library(dplyr)
library(ggplot2)
library(lubridate)
library(forcats)
library(viridis)  # This package provides color palettes that are perceptually uniform

# Assuming your dataframe is named df
# and df$order_purchase_timestamp, df$product_category_name_english, and df$payment_value are available

# Ensure payment_value is numeric
df$payment_value <- as.numeric(df$payment_value)

# Convert order_purchase_timestamp to Date and extract year and month
df <- df %>%
  mutate(
    order_purchase_timestamp = as.Date(order_purchase_timestamp),
    year_month = format(order_purchase_timestamp, "%Y-%m")
  )

# Calculate monthly revenue by category
monthly_revenue_by_category <- df %>%
  group_by(year_month, product_category_name_english) %>%
  summarise(monthly_revenue = sum(payment_value), .groups = "drop")

# Find the top 20 categories by total revenue in 2017
top_categories <- monthly_revenue_by_category %>%
  filter(substr(year_month, 1, 4) == "2017") %>%
  group_by(product_category_name_english) %>%
  summarise(total_revenue = sum(monthly_revenue), .groups = "drop") %>%
  top_n(20, total_revenue) %>%
  arrange(desc(total_revenue)) %>%
  pull(product_category_name_english)

# Add an "Other" category for those not in the top 20
monthly_revenue_by_category <- monthly_revenue_by_category %>%
  mutate(
    category_grouped = if_else(product_category_name_english %in% top_categories,
                               as.character(product_category_name_english), "Other")
  )

# Recalculate monthly revenue by the new grouped category
monthly_revenue_grouped <- monthly_revenue_by_category %>%
  group_by(year_month, category_grouped) %>%
  summarise(monthly_revenue = sum(monthly_revenue), .groups = "drop")

# Ensure the entire time period is included
monthly_revenue_grouped <- monthly_revenue_grouped %>%
  filter(year_month >= "2017-01", year_month <= "2018-08")

# Create a custom color palette using the viridis package
num_categories <- length(unique(monthly_revenue_grouped$category_grouped))
colors <- viridis(num_categories, option = "D")

# Order categories by total revenue in 2017
category_order <- monthly_revenue_grouped %>%
  filter(year_month < "2018-01") %>%
  group_by(category_grouped) %>%
  summarise(total_revenue_2017 = sum(monthly_revenue), .groups = "drop") %>%
  arrange(desc(total_revenue_2017)) %>%
  pull(category_grouped)

monthly_revenue_grouped$category_grouped <- factor(monthly_revenue_grouped$category_grouped, levels = category_order)

# Create the stacked area chart showing share of total revenue
ggplot(monthly_revenue_grouped, aes(x = as.Date(paste0(year_month, "-01")), y = monthly_revenue, fill = category_grouped)) +
  geom_area(position = 'fill') +  # Use 'fill' to show share of total revenue
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
  scale_fill_manual(values = setNames(colors, category_order)) +
  labs(title = "Monthly Revenue Share by Top 20 Product Categories in 2017 and Others",
       x = "Month", y = "Revenue Share (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill=guide_legend(title="Product Category"))

```

```{r}
# Check HHI to see market concentration over time for products, customers, sellers and customer location (city)

library(dplyr)
library(ggplot2)
library(lubridate)

# Convert the order_purchase_timestamp to Date format and extract year-month
df <- ord_cust_pay_geo_prod %>%
  mutate(
    order_purchase_timestamp = as.Date(order_purchase_timestamp),
    year_month = format(order_purchase_timestamp, "%Y-%m")
  )

# Define a function to calculate monthly HHI
calculate_monthly_HHI <- function(data, group_col) {
  data %>%
    group_by(year_month, !!group_col) %>%
    summarise(total_sales = sum(payment_value), .groups = "drop") %>%
    group_by(year_month) %>%
    mutate(market_share = total_sales / sum(total_sales)) %>%
    summarise(HHI = sum(market_share^2), .groups = "drop")
}

# Calculate monthly HHI for products, customers, sellers, and cities
HHI_products_monthly <- calculate_monthly_HHI(df, sym("product_id")) 
  

HHI_customers_monthly <- calculate_monthly_HHI(df, sym("customer_unique_id"))

HHI_sellers_monthly <- calculate_monthly_HHI(df, sym("seller_id"))

HHI_cities_monthly <- calculate_monthly_HHI(df, sym("customer_city")) 

# Plotting the HHIs over time
ggplot() +
  geom_line(data = HHI_products_monthly, aes(x = as.Date(paste0(year_month, "-01")), y = HHI, colour = "Products")) +
  geom_line(data = HHI_customers_monthly, aes(x = as.Date(paste0(year_month, "-01")), y = HHI, colour = "Customers")) +
  geom_line(data = HHI_sellers_monthly, aes(x = as.Date(paste0(year_month, "-01")), y = HHI, colour = "Sellers")) +
  geom_line(data = HHI_cities_monthly, aes(x = as.Date(paste0(year_month, "-01")), y = HHI, colour = "Cities")) +
  scale_x_date(limits = as.Date(c("2017-01-01", "2018-08-31"))) +
  labs(title = "Monthly HHI for Products, Customers, Sellers, and Cities",
       x = "Time", y = "HHI",  # Update the y-axis label
       colour = "Category") +
  theme_minimal() +
  scale_colour_manual(values = c("Products" = "blue", "Customers" = "red", "Sellers" = "green", "Cities" = "purple"))

```

```{r}
# Filter for orders from Sao Paulo only and calculate market share
market_share_sao_paulo_monthly <- df %>%
  filter(customer_city == "sao paulo") %>%
  group_by(year_month) %>%
  summarise(
    total_sales_sao_paulo = sum(payment_value),
    total_sales_overall = sum(df %>% filter(year_month == first(year_month)) %>% pull(payment_value)),
    .groups = "drop"
  ) %>%
  mutate(market_share_sao_paulo = total_sales_sao_paulo / total_sales_overall)

# View the market share of Sao Paulo per year-month
print(market_share_sao_paulo_monthly)

```


```{r}
# Look at avg revenue per seller since sellers are the customers

# Filter to delivered orders only
# geo_df_delivered = geo_df %>%
#   filter(geo_df$order_status == "delivered")

# Group by seller id and sum p * Q and freight * Q
rev_by_seller = geo_df_delivered %>%
  mutate(
    order_purchase_timestamp = as.Date(order_purchase_timestamp),
    month = floor_date(order_purchase_timestamp, "month")) %>%
  group_by(seller_id, month) %>%
  summarise(
    product_revenue = sum(price * units_ordered),
    shipping_revenue = sum(freight_value * units_ordered),
    .groups = "drop"
  ) %>%
  mutate(total_revenue = product_revenue + shipping_revenue)

avg_rev_by_seller = rev_by_seller %>%
  group_by(month) %>%
  summarise(
    avg_product_revenue = mean(product_revenue),
    avg_shipping_revenue = mean(shipping_revenue),
    avg_total_revenue = mean(total_revenue),
    .groups = "drop"
  )

# Plot stacked area chart
library(tidyr)

avg_rev_by_seller_long = avg_rev_by_seller %>%
  pivot_longer(
    cols = c(avg_product_revenue, avg_shipping_revenue),
    names_to = "revenue_type", 
    values_to = "amount"
  )

ggplot(avg_rev_by_seller_long, aes(x = month, y = amount, fill = revenue_type)) +
  geom_area(position = "stack", stat = "identity") +
  scale_fill_brewer(palette = "Pastel1")
  labs(
    title = "Revenue Breakdown By Seller Per Month",
    x = "Month",
    y = "Revenue",
    fill = "Revenue Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.x = element_blank())  


```

```{r}
# Look at seller growth broken down by new vs old sellers

first_sales_dates = geo_df_delivered %>%
  group_by(seller_id) %>%
  summarise(first_sale_date = min(as.Date(order_purchase_timestamp))) %>%
  ungroup()

geo_df_delivered = geo_df_delivered %>%
  mutate(order_purchase_timestamp = as.Date(order_purchase_timestamp)) %>%
  left_join(first_sales_dates, by = "seller_id")

# Categorize new vs old sellers
geo_df_delivered = geo_df_delivered %>%
  mutate(
    month = floor_date(order_purchase_timestamp,"month"),
    seller_new_old = if_else(month == floor_date(first_sale_date.x, "month"), "New", "Old")
  )

# Count new vs old per month
sellers_per_month = geo_df_delivered %>%
  group_by(month, seller_new_old) %>%
  summarize(total_sellers = n_distinct(seller_id), .groups= "drop")

# Plot
ggplot(sellers_per_month, aes(x = month, y = total_sellers, fill = seller_new_old)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_brewer(palette = "Pastel1") +
  labs(
    title = "Total Sellers per Month: New vs Old",
    x = "Month",
    y = "Total Sellers",
    fill = "Seller Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# saveRDS(sellers_per_month, "sellers_new_old.rds")
str(sellers_per_month)
```

```{r}
library(dplyr)
library(lubridate)

# Assuming monthly_revenue_pxq and monthly_seller_stats are already created and contain the necessary data

# Calc monthly total revenue
monthly_revenue_pxq = geo_df_delivered %>%
  group_by(month) %>%
  summarize(
    total_payment_value = sum(payment_value),
    total_revenue = sum(price + freight_value * units_ordered)
  ) %>%
  ungroup()

# Calc number of sellers per month
monthly_sellers = geo_df_delivered %>%
  group_by(month) %>%
  summarise(total_sellers = n_distinct(seller_id)) %>%
  ungroup()
# Merge monthly_revenue_pxq with monthly_seller_stats to include total_sellers_subscribed
revenue_sellers_df <- left_join(monthly_revenue_pxq, monthly_seller_stats %>% select(month, total_sellers_subscribed), by = "month") %>%
  mutate(
    avg_revenue_payment = total_payment_value / total_sellers_subscribed, 
    avg_revenue_calc = total_revenue / total_sellers_subscribed
  )

# Filter to Jan 2017 to Aug 2018
filtered_seller_df = revenue_sellers_df %>%
  filter(month >= as.Date("2017-01-01") & month <= as.Date("2018-08-31"))

# Calculate base values using January 2017 data
base_month = as.Date("2017-01-01")
base_values = filtered_seller_df %>%
  filter(month == base_month) %>%
  summarise(
    base_total_revenue = first(total_revenue),
    base_total_sellers_subscribed = first(total_sellers_subscribed),
    base_avg_revenue_calc = first(avg_revenue_calc)
  )

# Extract base values
base_total_revenue = base_values$base_total_revenue
base_total_sellers_subscribed = base_values$base_total_sellers_subscribed
base_avg_revenue_calc = base_values$base_avg_revenue_calc

# Calculate indices based on the base values
filtered_seller_indexes = filtered_seller_df %>%
  mutate(
    revenue_index = (total_revenue / base_total_revenue) * 100, 
    sellers_index = (total_sellers_subscribed / base_total_sellers_subscribed) * 100,
    avg_revenue_index = (avg_revenue_calc / base_avg_revenue_calc) * 100
  )

saveRDS(filtered_seller_indexes,"filtered_seller_indexes.rds")

# Plot
ggplot(filtered_seller_indexes, aes(x = month)) +
  geom_line(aes(y = revenue_index, color = "Total Revenue"), size = 1) +
  geom_line(aes(y = sellers_index, color = "Total Sellers"), size = 1) +
  geom_line(aes(y = avg_revenue_index, color = "Avg Revenue Per Seller"), size = 1) +
  scale_color_manual(values = c("Total Revenue" = "blue", "Total Sellers" = "red", "Avg Revenue Per Seller" = "green")) +
  labs(title = "Total Revenue, Total Sellers and Avg Revenue Per Seller",
       x = "Month", y = "Index (Base 100)", color = "Legend Title") +
  theme_gray() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```



```{r}
# Assuming 'filtered_seller_indexes' is your original dataset
library(tidyr)
library(ggplot2)

# Reshape the data to long format
long_data <- pivot_longer(filtered_seller_indexes, 
                          cols = c(revenue_index, sellers_index, avg_revenue_index), 
                          names_to = "Category", 
                          values_to = "Value")

# Adjust the names to more readable forms if necessary
long_data$Category <- recode(long_data$Category, 
                             revenue_index = "Total Revenue", 
                             sellers_index = "Total Sellers", 
                             avg_revenue_index = "Avg Revenue Per Seller")

# Plot
ggplot(long_data, aes(x = month, y = Value, color = Category)) +
  geom_line(size = 1) +
  # scale_color_manual(values = c("Total Revenue" = "blue", "Total Sellers" = "red", "Avg Revenue Per Seller" = "green")) +
  labs(title = "Total Revenue, Total Sellers and Avg Revenue Per Seller",
       x = "Month", y = "Index (Base 100)", color = "Legend Title") +
  theme_gray() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r}
saveRDS(long_data, "index_summary_df.rds")
```

```{r}
getwd()
```


```{r}
install.packages("googleCharts")
saveRDS(filtered_seller_indexes, "filtered_seller_indexes.rds")

str(filtered_seller_indexes$month)
```


```{r}
# Check out seller competitiveness if possible

# First check if there are multiple sellers of the same product
sellers_per_product = geo_df_delivered %>%
  group_by(product_id) %>%
  summarise(num_sellers = n_distinct(seller_id)) %>%
  ungroup()

# There are multiple sellers per product so move on to calc avg num of sellers per product per month

monthly_sellers_per_product = geo_df_delivered %>%
  mutate(month = floor_date(as.Date(order_purchase_timestamp), "month")) %>%
  group_by(month, product_id) %>%
  summarise(num_sellers = n_distinct(seller_id), .groups = "drop")

avg_sellers_per_product_monthly = monthly_sellers_per_product %>%
  group_by(month) %>%
  summarize(avg_sellers = mean(num_sellers), .groups = "drop")

# Plot
ggplot(avg_sellers_per_product_monthly, aes(x = month, y = avg_sellers)) +
  geom_line() +
  labs(title = "Avg Sellers Per Product Per Month",
       x = "Month",
       y = "Avg Number of Sellers") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
saveRDS(geo_df_delivered, "geo_df_delivered.rds")
```

```{r}
str(geo_df_delivered)
```

