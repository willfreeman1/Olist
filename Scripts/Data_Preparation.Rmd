```{r}

setwd("C:/Users/willf/OneDrive/Documents/NYDSA/R/Olist/Data")
# First load all the csv files in the dataset
orders = read.csv("olist_orders_dataset.csv")
customers = read.csv("olist_customers_dataset.csv")
geolocation = read.csv("olist_geolocation_dataset.csv")
order_items = read.csv('olist_order_items_dataset.csv')
order_payments = read.csv("olist_order_payments_dataset.csv")
order_reviews = read.csv("olist_order_reviews_dataset.csv")
products = read.csv("olist_products_dataset.csv")
sellers = read.csv("olist_sellers_dataset.csv")
cat_name_translation = read.csv("product_category_name_translation.csv")
```

```{r}

# Prep geolocation data to add to main DF

# first summarize avg lon/lat per zip code prefix

geo_summary = geolocation %>%
  group_by(geolocation_zip_code_prefix) %>%
  summarise(
    avg_longitude = mean(geolocation_lng, na.rm = TRUE),
    avg_latitude = mean(geolocation_lat, na.rm = TRUE)
  ) %>%
  ungroup()

# join geo_summary with customer data and then seller data

customers = customers %>%
  left_join(geo_summary, by = c("customer_zip_code_prefix" = "geolocation_zip_code_prefix")) %>%
  rename(
    customer_longitude = avg_longitude,
    customer_latitude = avg_latitude
  )

sellers = sellers %>%
  left_join(geo_summary, by = c("seller_zip_code_prefix" = "geolocation_zip_code_prefix")) %>% 
   rename(
    seller_longitude = avg_longitude,
    seller_latitude = avg_latitude
  )
```


```{r}

# Join CSVs into one dataframe

library(dplyr)

orders_customers = orders %>%
  left_join(customers, by = "customer_id")

cust_orditems = orders_customers %>%
  left_join(order_items, by = "order_id")

cust_ords_prods = cust_orditems %>%
  left_join(products, by = "product_id")

cust_ords_prods_sells = cust_ords_prods %>%
  left_join(sellers, by = "seller_id")

cust_ords_prods_sells_pays = cust_ords_prods_sells %>%
  left_join(order_payments, by = "order_id")

cust_ords_prods_sells_pays_reviews = cust_ords_prods_sells_pays %>%
  left_join(order_reviews, by = "order_id")

full_df = cust_ords_prods_sells_pays_reviews %>%
  left_join(cat_name_translation, by = "product_category_name")

```
```{r}
# Run validations to make sure data successfully and correctly aggregated into full_df

# rows in full_df should be equal to or greater than rows in orders
print(paste("Rows in orders:", nrow(orders)))
print(paste("Rows in full_df:", nrow(full_df)))

# check if all order IDs are in full_df
all(orders$order_id %in% full_df$order_id)

# check null values
colSums(is.na(full_df))

na_cust_geo = full_df[is.na(full_df$customer_longitude) | is.na(full_df$customer_latitude),]

na_item_id = full_df[is.na(full_df$order_item_id) | is.na(full_df$product_id),]

na_dimweight = full_df[is.na(full_df$product_weight_g) | is.na(full_df$product_length_cm),]
```
```{r}
# Found a number of NA cells so I want to confirm they are as they should be. Here I'm making sure that when customer longitude and latitude are blank that is indeed because there as no match between the customer zip code and the geolocation zip code

na_cust_zips = unique(na_cust_geo$customer_zip_code_prefix)

missing_cust_zips = na_cust_zips[!na_cust_zips %in% geolocation$geolocation_zip_code_prefix]

print(length(na_cust_zips))
print(length(missing_cust_zips))
```

```{r}
# More validation - summarize full_df

summary(full_df)
```

```{r}
# Convert dates from character classes to date-time objects

library(lubridate)

full_df$order_purchase_timestamp = ymd_hms(full_df$order_purchase_timestamp)

full_df$order_approved_at = ymd_hms(full_df$order_approved_at)

full_df$order_delivered_carrier_date = ymd_hms(full_df$order_delivered_carrier_date)

full_df$order_delivered_customer_date = ymd_hms(full_df$order_delivered_customer_date)

full_df$order_estimated_delivery_date = ymd_hms(full_df$order_estimated_delivery_date)

full_df$shipping_limit_date = ymd_hms(full_df$shipping_limit_date)

class(full_df$shipping_limit_date)
```
```{r}
# Duplicate order_id inspection to see where differences are

library(dplyr)
library(purrr)
library(tidyr)

duplicated_order_ids = full_df %>%
  filter(duplicated(order_id) | duplicated(order_id, fromLast = TRUE))


# func to check differences in each column
check_differences = function(df, column) {
  column_data <- df[[column]]
  if (is.numeric(column_data) || is.character(column_data) || is.logical(column_data)) {
    return(any(column_data != column_data[1]))
  } else if (is.factor(column_data)) {
    return(any(as.character(column_data) != as.character(column_data[1])))
  } else if (inherits(column_data, "Date") || inherits(column_data, "POSIXct")) {
    return(any(as.character(column_data) != as.character(column_data[1])))
  } else {
    return(FALSE)
  }
}

other_columns = setdiff(names(duplicated_order_ids), "order_id")

col_diffs = duplicated_order_ids %>%
  group_by(order_id) %>%
  summarise(across(all_of(other_columns), ~check_differences(cur_data(), cur_column())))

# Convert results to readable format
col_diffs_per_orderid = col_diffs %>%
  pivot_longer(cols = -order_id, names_to = "column", values_to = "differs") %>%
  filter(differs)

View(col_diffs_per_orderid)

```
```{r}
write.csv(duplicated_order_ids,"duplicated_orderids.csv")
```

```{r}
library(stringi)
library(dplyr)

duplicated_order_ids = duplicated_order_ids %>%
  mutate(row_identifier = apply(select(., -order_id), 1, function(x) stri_join(x, collapse = "_")))

col_diffs_per_orderid = duplicated_order_ids %>%
  group_by(order_id) %>%
  summarise(differing_rows = n_distinct(row_identifier) > 1) %>%
  filter(differing_rows) %>%
  ungroup()

View(col_diffs_per_orderid)
```

```{r}
# Save full_df as an RDS file for easy access in other analysis scripts

saveRDS(full_df, file = "C:\\Users\\willf\\OneDrive\\Documents\\NYDSA\\R\\Olist\\Data\\full_df.rds")
```

