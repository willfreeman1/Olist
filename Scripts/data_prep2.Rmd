---
title: "R Notebook"
output: html_notebook
---

```{r}
setwd("C:/Users/willf/OneDrive/Documents/NYDSA/R/Olist/Data")
# First load all the csv files in the dataset
orders = read.csv("olist_orders_dataset.csv")
customers = read.csv("olist_customers_dataset.csv")
geolocation = read.csv("olist_geolocation_dataset.csv")
order_items = read.csv('olist_order_items_dataset.csv')
order_payments = read.csv("olist_order_payments_dataset.csv")
order_reviews = read.csv("olist_order_reviews_dataset.csv")
products = read.csv("olist_products_dataset.csv")
sellers = read.csv("olist_sellers_dataset.csv")
cat_name_translation = read.csv("product_category_name_translation.csv")
```

```{r}
# Join orders and order_items
library(dplyr)
library(tidyr)

orders_items = merge(orders, order_items, by = "order_id")

# Select columns
orders_items_check <- orders_items %>%
  select(order_id, product_id, order_purchase_timestamp, order_item_id, price, freight_value)

# Filter for instances with more than one of the same order_id
orders_items_duplicated <- orders_items_check %>%
  group_by(order_id) %>%
  filter(n() > 1) %>%
  ungroup()  # Ungroup for further analysis if needed

# write.csv(orders_items_duplicated, "orders_items_duplicated.csv")


```

```{r}
# Check if there are duplicate order_ids in order_payments

distinct_order_ids = n_distinct(order_payments$order_id)

total_rows = nrow(order_payments)

print(distinct_order_ids)
print(total_rows)

order_payments_duplicated <- order_payments %>%
  group_by(order_id) %>%
  filter(n() > 1) %>%
  ungroup()  # Ungroup for further analysis if needed

# write.csv(order_payments_duplicated, "orders_ipayments_duplicated.csv")
```

```{r}
# Merge orders_items with payments

library(dplyr)

orders_items_payments = left_join(orders_items, order_payments, by = "order_id")

# write.csv(orders_items_payments, "orders_items_payments.csv")
```

```{r}
# Now I'll consolidate rows where the only difference is order_item_id 

consolidated_orders <- orders_items_payments %>%
  group_by_at(vars(-order_item_id)) %>%
  summarise(units_ordered = n(), .groups = "drop") %>%
  arrange(order_id)        
```

```{r}
# Check that consolidated orders still contains all the same order IDs as orders_items_payments

unique_order_ids_original = unique(orders_items_payments$order_id)
unique_order_ids_consolidated = unique(consolidated_orders$order_id)

id_check = all(unique_order_ids_original %in% unique_order_ids_consolidated)

print(id_check)

```


```{r}
library(stringr)


# Next adding customers DF 
consolidated_orders_customers = left_join(consolidated_orders, customers, by = "customer_id")

# Prep and add geolocation DF - 

# First add leading zeroes to prefixes that were accidentally missing

geolocation = geolocation %>%
  mutate(geolocation_zip_code_prefix = str_pad(geolocation_zip_code_prefix, width = 5, side = "left", pad = "0"))

# Then filter for codes in Brazil and take averages of lat / long per prefix

geolocation = geolocation %>%
  filter(
    geolocation_lat <= 5.27438888,
    geolocation_lng >= -73.98283055,
    geolocation_lat >= -33.75116944,
    geolocation_lng <= -34.79314722
  ) %>%
  group_by(geolocation_zip_code_prefix) %>%
  summarise(
    geolocation_lat = mean(geolocation_lat),
    geolocation_lng = mean(geolocation_lng),
    geolocation_city = first(geolocation_city),
    geolocation_state = first(geolocation_state),
    .groups = "drop"
  )

# Add the leading zeroes back to the consolidated_orders_customers DF

consolidated_orders_customers = consolidated_orders_customers %>%
  mutate(customer_zip_code_prefix = str_pad(customer_zip_code_prefix, width = 5, side = "left", pad = "0"))

# Join the two DFs to create the final dataframe for RMF and Customer Segmentation 

ord_cust_pay_geo <- left_join(consolidated_orders_customers, geolocation, by = c("customer_zip_code_prefix" = "geolocation_zip_code_prefix"))

```

```{r}
# Next join the products DF

ord_cust_pay_geo_prod = left_join(ord_cust_pay_geo, products, by = "product_id")
```
```{r}
# Investigate reviews DF
# Count reviews per order id
review_counts = order_reviews %>%
  group_by(order_id) %>%
  summarize(ReviewCount = n())

# Check for orders with multiple ids
multiple_reviews = review_counts %>%
  filter(ReviewCount > 1)

head(multiple_reviews)


# join the reviews DF

ord_cust_pay_geo_prod_rev = left_join(ord_cust_pay_geo_prod, order_reviews, by = "order_id")

# investigate why number of rows increased by 600+ for last join

unique_orders_before = n_distinct(ord_cust_pay_geo_prod$order_id)
unique_review_order_ids = n_distinct(order_reviews$order_id)
unique_orders_after = n_distinct(ord_cust_pay_geo_prod_rev$order_id)

unique_orders_before
unique_review_order_ids
unique_orders_after

# Check for order IDs in `order_reviews` not present in `ord_cust_pay_geo_prod`
missing_orders_in_reviews <- setdiff(order_reviews$order_id, ord_cust_pay_geo_prod$order_id)

# Check for order IDs in `ord_cust_pay_geo_prod` not present in `order_reviews`
missing_orders_in_ord_cust <- setdiff(ord_cust_pay_geo_prod$order_id, order_reviews$order_id)

print(missing_orders_in_ord_cust)

# View the results
length(missing_orders_in_reviews)
length(missing_orders_in_ord_cust)

# Identify the additional rows
additional_rows <- ord_cust_pay_geo_prod_rev %>%
  filter(!order_id %in% ord_cust_pay_geo_prod$order_id)

# View the first few rows
head(additional_rows)

# Filter order_reviews to include only missing order IDs
filtered_order_reviews <- order_reviews %>%
  filter(order_id %in% missing_orders_in_reviews)

# View the filtered order_reviews dataframe
head(filtered_order_reviews)

library(dplyr)

# Find rows in order_reviews that have order IDs not in ord_cust_pay_geo_prod
missing_reviews <- order_reviews %>%
  anti_join(ord_cust_pay_geo_prod, by = "order_id")

# View the missing_reviews dataframe
head(missing_reviews)

# Check for order IDs in `order_reviews` not present in `ord_cust_pay_geo_prod`
missing_orders_in_reviews <- setdiff(order_reviews$order_id, ord_cust_pay_geo_prod$order_id)

# View the length of missing_orders_in_reviews
length(missing_orders_in_reviews)

# Filter order_reviews to include only missing order IDs
missing_reviews <- order_reviews %>%
  filter(order_id %in% missing_orders_in_reviews)

# View the missing_reviews dataframe
head(missing_reviews)

# Filter order_reviews to include only missing order IDs
missing_reviews <- order_reviews %>%
  filter(order_id %in% missing_orders_in_reviews)

# View all reviews for those order IDs
print(missing_reviews)

write.csv(missing_reviews, "missing_reviews.csv")
write.csv(ord_cust_pay_geo_prod, "ord_cust_pay_geo_prod.csv")
write.csv(ord_cust_pay_geo_prod_rev, "ord_cust_pay_geo_prod_rev.csv")

```

```{r}
# Now integrate the censobr and geobr data to get population, income and income per capita per zip code

library(censobr)
library(geobr)
library(dplyr)
library(arrow)
library(ggplot2)

# data_dictionary(year = 2010, dataset = 'tracts')


# download data
tract_basico <- read_tracts(year = 2010,
                            dataset = "Basico", 
                            showProgress = FALSE)

tract_income <- read_tracts(year = 2010,
                            dataset = "DomicilioRenda", 
                            showProgress = FALSE)

# select columns
tract_basico <- tract_basico |> select('code_tract','V002')
tract_income <- tract_income |> select('code_tract','V003')

# merge
tracts_df <- left_join(tract_basico, tract_income) |> collect()

# calculate income per capita
tracts_df <- tracts_df |> mutate(income_pc = V003 / V002)
head(tracts_df)

```

```{r}
# Rename pop and income columns
tracts_df = tracts_df %>%
  rename(income = V003, population = V002)

head(tracts_df)

```

```{r}
head(tract_basico)
```

