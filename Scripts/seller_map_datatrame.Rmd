Data for Leaflet Map Visualizations

# DIVIDE FULL SELLER DATA DF INTO DF BY SELLER ID, DF BY ZIP AND DF BY MUNI
  Seller Data:Zip Code; Muni_Name; Zip geom point; muni geom; LTV (first/last order date, months active, total sales);Urban v rural; avg ship share of price; avg review score

```{r}
getwd()
full_seller_data = readRDS("..//Data/full_seller_data.rds")
```

```{r}
# CREATE DF BY SELLER ID - calc first/last order date per seller, months active)

# Calc months subscribed
library(dplyr)
library(lubridate)

seller_subscription_dates <- full_seller_data %>%
  group_by(seller_id) %>%
  summarise(
    subscription_start = min(order_purchase_timestamp, na.rm = TRUE),
    subscription_end = max(order_purchase_timestamp, na.rm = TRUE)
  ) %>%
  mutate(
    subscription_start = floor_date(subscription_start, "month"),
    subscription_end = ceiling_date(subscription_end, "month") - days(1),
    # Calculate the number of whole months
    subscription_months = round(time_length(interval(subscription_start, subscription_end), "months"))
  ) %>%
  ungroup()

```

```{r}
# calc seller map features
seller_map_df <- full_seller_data %>%
  group_by(seller_id) %>%
  summarise(
    seller_zip = first(na.omit(seller_zip_code_prefix)),
    seller_city = first(na.omit(geolocation_city)),
    seller_state = first(na.omit(geolocation_state)),
    zone = first(na.omit(zone)),
    muni_name = first(na.omit(name_muni)),
    muni_geom = first(na.omit(geom_munis)),
    latitude = first(na.omit(latitude)),
    longitude = first(na.omit(longitude)),
    zip_point = first(na.omit(sell_geometry)),
    seller_zip_population = first(na.omit(population)),
    seller_zip_income = first(na.omit(income)),
    seller_zip_incomepc = first(na.omit(income_pc)),
    unique_products_sold = n_distinct(product_id),
    avg_price = mean(price),
    total_sales = sum(price),
    avg_freight = mean(freight_value),
    total_freight = sum(freight_value),
    total_revenue = sum(price + freight_value),
    avg_ship_share = mean(freight_value / price) * 100,
    avg_expected_ship_time = mean(as.numeric(floor_date(order_estimated_delivery_date, "day") - floor_date(order_purchase_timestamp, "day"))),
    avg_ship_time = mean(as.numeric(floor_date(order_delivered_customer_date, "day") - floor_date(order_purchase_timestamp, "day"))),
    total_orders = n_distinct(order_id),
    avg_review_score = mean(review_score))

# Create prodcat_rev_share dataframe

library(tidyr)


top_prodcats_seller <- full_seller_data %>%
  group_by(seller_id, product_category_name_english) %>%
  summarise(revenue = sum(price, na.rm = TRUE)) %>%
  filter(!is.na(product_category_name_english)) %>%
  arrange(seller_id, desc(revenue)) %>%
  mutate(rank = row_number()) %>%
  filter(rank <= 3) %>%
  select(seller_id, product_category_name_english, rank) %>%  # Select only necessary columns
  pivot_wider(names_from = rank, values_from = product_category_name_english,
              names_prefix = "category_",
              values_fill = list(product_category_name_english = NA))

# Join
seller_map_df <- seller_map_df %>%
  left_join(top_prodcats_seller, by = "seller_id")

# Join subscription time
seller_map_df <- seller_map_df %>%
  left_join(seller_subscription_dates, by = "seller_id")

# Calc Seller LTV
seller_map_df <- seller_map_df %>%
  mutate(seller_LTV = (subscription_months * 99) + (total_sales * 0.2))

```


```{r}
saveRDS(seller_map_df, "..//Data//seller_map_df.rds")

seller_map_exgeom <- seller_map_df %>%
  select(-muni_geom, zip_point)
write.csv(seller_map_exgeom, "..//Data//seller_map_exgeom.csv")
```


```{r}
# Check for correlations with seller_LTV

library(ggplot2)

# Assuming seller_map_df has columns unique_products_sold and seller_LTV
# Calculate correlation coefficient
cor_coeff <- cor(seller_map_df$avg_ship_share, seller_map_df$total_sales, use = "complete.obs")

# Create the plot
ggplot(seller_map_df, aes(x = avg_ship_share, y = total_sales)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Add best fit line without standard error
  annotate("text", x = Inf, y = Inf, label = paste("Correlation: ", round(cor_coeff, 2)), 
           hjust = 1.1, vjust = 1.1, size = 4, color = "blue")  # Annotate with correlation

```

```{r}
# Lorenz Curve of Seller LTV Concentration

library(ggplot2)

# Ensure your data is sorted
seller_map_df <- seller_map_df[order(seller_map_df$seller_LTV), ]

# Calculate cumulative sums
seller_map_df$cumulative_LTV <- cumsum(seller_map_df$seller_LTV)
seller_map_df$cumulative_sellers <- seq_along(seller_map_df$seller_LTV)

# Normalize to get percentages
seller_map_df$cumulative_LTV <- seller_map_df$cumulative_LTV / max(seller_map_df$cumulative_LTV)
seller_map_df$cumulative_sellers <- seller_map_df$cumulative_sellers / length(seller_map_df$cumulative_sellers)

# Plot
ggplot(seller_map_df, aes(x = cumulative_sellers, y = cumulative_LTV)) +
  geom_line() +
  labs(x = "Cumulative Share of Sellers", y = "Cumulative Share of Seller LTV",
       title = "Lorenz Curve of Seller LTV") +
  theme_minimal()


```

```{r}
# Pareto of seller LTV concentration
library(ggplot2)
library(dplyr)

# Sort and mutate to add cumulative sum
seller_map_df <- seller_map_df %>%
  arrange(desc(seller_LTV)) %>%
  mutate(cumulative_LTV = cumsum(seller_LTV) / sum(seller_LTV))

# Create the Pareto Chart
ggplot(seller_map_df, aes(x = reorder(seller_id, seller_LTV), y = seller_LTV)) +
  geom_bar(stat = "identity") +
  geom_line(aes(y = cumulative_LTV), group = 1, color = "blue") +
  scale_y_continuous(sec.axis = sec_axis(~ . * max(seller_map_df$seller_LTV), name = "Cumulative LTV")) +
  labs(x = "Seller", y = "Seller LTV", 
       title = "Pareto Chart of Seller LTV") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r}
# Calc per seller share of total LTV

seller_map_df <- seller_map_df %>%
  mutate(seller_LTV_share = seller_LTV / sum(seller_LTV) * 100)

# Same by muni

muni_map_sf <- muni_map_sf %>%
  mutate(muni_LTV_share = total_seller_LTV / sum(total_seller_LTV) * 100)

```

